alibaba.bucket.create.dialog.hierarchical.field=Иерархическое пространство имён
alibaba.bucket.create.dialog.versioning=Включить версионирование
alibaba.custom.endpoint.text=Пользовательский
alibaba.region.oss-ap-northeast-1=Япония (Токио)
alibaba.region.oss-ap-northeast-2=Корея (Сеул)
alibaba.region.oss-ap-south-1=Индия (Мумбаи)
alibaba.region.oss-ap-southeast-1=Австралия (Сидней) 1
alibaba.region.oss-ap-southeast-2=Австралия (Сидней) 2
alibaba.region.oss-ap-southeast-3=Малайзия (Куала-Лумпур)
alibaba.region.oss-ap-southeast-5=Индонезия (Джакарта)
alibaba.region.oss-ap-southeast-6=Филиппины (Манила)
alibaba.region.oss-ap-southeast-7=Таиланд (Бангкок)
alibaba.region.oss-cn-beijing=Китай (Пекин)
alibaba.region.oss-cn-chengdu=Китай (Чэнду)
alibaba.region.oss-cn-guangzhou=Китай (Гуанчжоу)
alibaba.region.oss-cn-hangzhou=Китай (Ханчжоу)
alibaba.region.oss-cn-heyuan=Китай (Хэюань)
alibaba.region.oss-cn-hongkong=Китай (Гонконг)
alibaba.region.oss-cn-huhehaote=Китай (Хух-Хото)
alibaba.region.oss-cn-nanjing=Китай (Нанкин - локальный регион)
alibaba.region.oss-cn-qingdao=Китай (Циндао)
alibaba.region.oss-cn-shanghai=Китай (Шанхай)
alibaba.region.oss-cn-shenzhen=Китай (Шэньчжэнь)
alibaba.region.oss-cn-wulanchabu=Китай (Уланчабу)
alibaba.region.oss-cn-zhangjiakou=Китай (Чжанцзякоу)
alibaba.region.oss-eu-central-1=Германия (Франкфурт)
alibaba.region.oss-eu-west-1=Великобритания (Лондон)
alibaba.region.oss-me-east-1=ОАЭ (Дубай)
alibaba.region.oss-us-east-1=США (Вирджиния)
alibaba.region.oss-us-west-1=США (Кремниевая долина)
alibaba.settings.credentials.file=Файл учетных данных Alibaba
alibaba.task.delete.bucket.text=Удаление бакета {0}
alibaba.task.delete.directory.text=Удаление директории {0}
alibaba.task.delete.directory.text2=Удалено объектов\: {0}
alibaba.task.delete.file.text=Удаление файла {0}
azure.column.name.access.tier=Уровень доступа
azure.rename.text2.indicator.deleting={0}\: Удаление {1}
bucket.name.is.empty.for.path=Имя бакета пусто для пути "{0}"
cannot.find.linode.region=Не удаётся найти регион для {0}
cannot.open.read.stream.null.blob=Не удаётся открыть поток чтения для null blob {0}
client.is.not.inited=Клиент не инициализован
connection.error.fs.and.user.not.found=Файловая система не найдена для URI {0} и пользователя {1}
connection.error.hadoop.home.is.not.defined.full=HADOOP_HOME не определен. В Windows вы должны определить переменную среды HADOOP_HOME или свойство Java hadoop.home.dir. Подробнее см. <a href\="https\://cwiki.apache.org/confluence/display/HADOOP2/WindowsProblems">Hadoop Wiki</a>.
connection.error.hadoop.no.native.drivers.full=Нативные драйверы не найдены в HADOOP_HOME. Подробнее см. <a href\="https\://cwiki.apache.org/confluence/display/HADOOP2/WindowsProblems">Hadoop Wiki</a>.
connection.error.root.path.must.be.non.empty=Корневой путь не может быть пустым
controller.cluster.instances.error=Ошибка обновления экземпляров кластера
controller.cluster.steps.error=Ошибка обновления шагов кластера
copy.failed=Не удалось скопировать из {0} в {1}
custom.bucket.text.empty=bucket/folder,bucket2/folder/subfolder2,…
custom.bucket.text.hint=Укажите список корневых источников через запятую (bucket1/folder1/folder2,bucket2/folder)
do.region.ams3=Амстердам, Нидерланды
do.region.blr1=Берлин, Германия
do.region.fra1=Франкфурт, Германия
do.region.nyc3=Нью-Йорк, США
do.region.sfo=Сан-Франциско, США
do.region.sgp1=Сингапур
do.region.syd1=Сидней, Австралия
emr.cluster.filter=Фильтр по статусу
emr.cluster.filter.limit=Лимит
emr.cluster.info.details=Показать как JSON
emr.cluster.terminate.cluster.message=Вы хотите завершить кластер {0}?
emr.cluster.terminate.cluster.title=Завершение кластера
emr.connection.creation=Создание подключения EMR
emr.connection.warning.no.clusters=Подключено, кластеры не найдены
emr.connection.warning.no.clusters.desc=Подключение установлено, но кластеры в выбранном регионе не найдены. Проверьте правильность региона.
emr.connection.warning.no.clusters.desc.window=Кластеры не найдены в регионе "{0}". Проверьте регион.
emr.dialog.title.select.key.info.cancel=Отмена
emr.dialog.title.select.key.info.msg=Для подключения требуется создать SSH-туннель. Выберите файл SSH-ключа для кластера.
emr.dialog.title.select.key.info.ok=Выбрать SSH-ключ
emr.dialog.title.select.key.info.title=Требуется SSH-ключ
emr.dialog.title.select.key.ssh.file=Выберите файл SSH-ключа
emr.error=Ошибка AWS EMR
emr.error.remove.cluster=Ошибка при удалении кластера
emr.error.start.cluster=Ошибка при запуске кластера
emr.error.stop.cluster=Ошибка при остановке кластера
emr.filter.text=Фильтр\:
emr.is.not.inited=Клиент EMR не инициализован
emr.key.storage.dialog.title=Хранилище SSH-ключей EMR
emr.keys.settings.column.key.name=Имя ключа
emr.keys.settings.column.key.path=Путь
emr.keys.settings.label=SSH-ключи\:
emr.keys.settings.table.empty=SSH-ключи не предоставлены
emr.label.choose.key.file.for.aws.pair=Выберите файл ключа для пары AWS {0}
emr.remove.linked.connections.action=Удалить подключение
emr.remove.linked.connections.desc=Вы хотите удалить подключения, созданные для EMR?
emr.remove.linked.connections.title=Подключение EMR
emr.spark.submit=EMR Spark-submit
emr.spark.submit.editor.args=Аргументы\:
emr.spark.submit.editor.jar.loc=Расположение JAR\:
emr.spark.submit.editor.name=Имя\:
emr.step.details=Показать детали шага
emr.step.mapper.choose=Выбрать Mapper
emr.step.reducer.choose=Выбрать Reducer
emr.step.s3.input.choose=Выбрать вход S3
emr.step.s3.output.choose=Выбрать выход S3
emr.step.script.choose=Выбрать расположение скрипта S3
emr.toolwindow.title=AWS EMR
error.krb5.conf=Не удалось авторизоваться через Kerberos. Попробуйте добавить "allow_weak_crypto \= true" в krb5.conf
error.object.summary.is.not.found=Сводка объекта не найдена для {0}
file.info.access.blob.type=Тип Blob
file.info.access.content.type=Тип контента
file.info.access.tier=Уровень доступа
file.info.access.tier.modified=Последнее изменение уровня доступа
gcs.buckets.source=Источник бакетов\:
gcs.connection.browse.title=Выберите JSON учетных данных
gcs.connection.error.bucket.validation1=Имя бакета должно содержать 3-63 символа. Имена с точками могут содержать до 222 символов, но каждый компонент не должен превышать 63 символа.
gcs.connection.error.bucket.validation2=Имя может содержать только строчные буквы, цифры, дефисы (-), подчеркивания (_) и точки (.).
gcs.connection.error.bucket.validation3=Имя бакета должно начинаться и заканчиваться цифрой или буквой.
gcs.connection.error.bucket.validation4=Имя бакета не может быть IP-адресом в десятичном формате с точками (например, 192.168.5.4).
gcs.connection.error.bucket.validation5=Имя бакета не может начинаться с префикса "goog".
gcs.connection.error.bucket.validation6=Имя бакета не может содержать "google" или похожие опечатки, например "g00gle".
gcs.connection.error.cred.file.not.selected=Необходимо выбрать файл учетных данных для аккаунта
gcs.connection.error.file.not.exists=Файл не существует
gcs.custom.url=Пользовательский хост\:
gcs.json.location.emptyText=Расположение JSON Cloud Storage
gcs.multibucket.update.text=Google Cloud Storage поддерживает множественные бакеты\! Вы можете настроить их в параметрах подключения.
gcs.multibucket.update.title=Новая функция GCS в BigDataTools
gcs.progress.details.deleting=Удаление {0}
gcs.project.id=ID проекта\:
gcs.project.id.emptyText=Опциональное переопределение ID проекта
gcs.project.id.hint=Показывать бакеты для определённого ID проекта
gcs.public.hint=Оставьте пустым для публичных бакетов
gcs.sdk.install=Google Cloud SDK не найден. <a>Установить</a>
gcs.sdk.update=Google Cloud SDK устарел. <a>Обновить</a>
group.name.alibaba=Alibaba OSS
group.name.azure=Azure
group.name.dospaces=DigitalOcean Spaces
group.name.emr=AWS EMR
group.name.gcs=Google Cloud Storage
group.name.hdfs.java=HDFS
group.name.linode=Linode
group.name.minio=MinIO
group.name.s3=AWS S3
group.name.yandex=Yandex Object Storage
group.names.hdfs.data=HDFS проблемы
hdfs.column.name.access.time=Время доступа
hdfs.column.name.block.size=Размер блока
hdfs.column.name.group=Группа
hdfs.column.name.is.encrypted=Зашифровано
hdfs.column.name.is.isErasureCoded=Erasure-кодование
hdfs.column.name.is.isSnapshotEnabled=Снапшот
hdfs.column.name.owner=Владелец
hdfs.column.name.permission=Права доступа
hdfs.column.name.replications=Репликации
hdfs.config.path.does.not.exist=Указанная директория не существует
hdfs.config.path.no.xmls.found=Указанная директория не содержит XML файлов
hdfs.config.path.not.empty=Путь конфигурации не должен быть пустым
hdfs.config.path.should.be.directory=Путь конфигурации должен указывать на директорию
hdfs.config.path.title=Путь конфигурации Java API
hdfs.field.root.path=Корневой путь
hdfs.file.info.label.accessTime=Время доступа\:
hdfs.file.info.label.block.size=Размер блока\:
hdfs.file.info.label.group=Группа\:
hdfs.file.info.label.isEncrypted=Зашифровано\:
hdfs.file.info.label.isErasureCoded=Erasure-кодование\:
hdfs.file.info.label.isSnapshotEnabled=Снапшоты включены\:
hdfs.file.info.label.modificationTime=Время изменения\:
hdfs.file.info.label.owner=Владелец\:
hdfs.file.info.label.permission=Права доступа\:
hdfs.file.info.label.replication=Репликации\:
hdfs.file.info.label.size=Размер\:
hdfs.is.not.inited=HDFS соединение не инициализовано
hdfs.java.config.source=Источник конфигурации\:
hdfs.java.driver.home.path=Домашний путь драйвера\:
hdfs.no.xmls.in.directory=Нет XML файлов в корне конфигурации
hdfs.property.source.directory=Директория конфигурации
hdfs.property.source.explicit=Пользовательский
hdfs.root.folder.does.not.exist=Корневая папка {0} не существует
hdfs.ssh.tunnel.ssh.operation.not.supported=Операция через SSH туннель не поддерживается.
inspection.java.custom.hdfs.format.display.name=Подсветка пользовательских форматов HDFS файлов
inspection.java.invalid.file.path.display.name=Подсветка некорректных путей HDFS файлов
inspection.kotlin.custom.hdfs.format.display.name=Подсветка пользовательских форматов HDFS файлов
inspection.kt.invalid.file.path.display.name=Подсветка некорректных путей HDFS файлов
inspection.non.serializable.data.in.scope.display.name=Подсветка несериализуемых данных в Spark задачах
inspection.scala.custom.hdfs.format.display.name=Подсветка пользовательских форматов HDFS файлов
inspection.scala.invalid.hdfs.file.path.display.name=Подсветка некорректных путей HDFS файлов
invalid.format.inspection.description=Подсветка пользовательских hdfs форматов. По умолчанию ожидаются форматы parquet, orc, sequence, json, csv или text.
invalid.format.inspection.template=Неожиданный пользовательский формат файла
java.wrong.path.inspection.description=Подсветка некорректных hdfs путей в Java коде
kerberos.type.credentials=Пароль
kerberos.type.disabled=Отключено
kerberos.type.keytab=Keytab
kerberos.type.subject=JAAS конфигурация (для экспертов)
kotlin.wrong.path.inspection.description=Подсветка некорректных hdfs путей в Kotlin коде
linode.region.ap-south=Сингапур
linode.region.br-gru-1=Сан-Паулу, Бразилия
linode.region.eu-central=Франкфурт, Германия
linode.region.fr-par-1=Париж, Франция
linode.region.id-cgk-1=Джакарта, Индонезия
linode.region.in-maa-1=Ченнаи, Индия
linode.region.it-mil-1=Милан, Италия
linode.region.jp-osa-1=Осака, Япония
linode.region.nl-ams-1=Амстердам, Нидерланды
linode.region.se-sto-1=Стокгольм, Швеция
linode.region.us-east=Ньюарк, Нью-Джерси, США
linode.region.us-iad-1=Вашингтон, округ Колумбия, США
linode.region.us-lax-1=Лос-Анджелес, Калифорния, США
linode.region.us-mia-1=Майами, Флорида, США
linode.region.us-ord-1=Чикаго, Иллинойс, США
linode.region.us-sea-1=Сиэтл, Вашингтон, США
linode.region.us-southeast=Атланта, Джорджия, США
metainfo.headers.empty=Нет пользовательских заголовков
metainfo.headers.key=Ключ
metainfo.headers.value=Значение
metainfo.section.custom.headers=Заголовки
minio.region.text.empty=Использовать по умолчанию
move.failed=Не удалось переместить из {0} в {1}.
notification.group.orc.files=ORC файлы
oss.file.info.label.hns.status=Иерархическое пространство имён\:
oss.file.info.label.hns.status.disabled=Отключено
oss.file.info.label.type=Content-Type\:
rfs.create.bucket.message=Создать bucket
s3.bucket.text.empty=Видны все bucket'ы
s3.bucket.text.hint=Если поле пустое, будут видны все bucket'ы<br>Введите имя bucket'а и выберите тип фильтра "Совпадение" для работы с одним bucket'ом<br>Используйте "," для разделения bucket'ов (bucket1, bucket2)
s3.column.name.etag=ETag
s3.column.name.metadata=Метаданные
s3.column.name.storage.class=Класс хранения
s3.connection.error.ssh.without.endpoint=Для использования SSH туннеля укажите endpoint для драйвера
s3.empty.directories.not.allowed=Создание пустых директорий не разрешено
s3.multibucket.open.settings=Открыть настройки
s3.multibucket.update.text=S3-совместимое хранилище поддерживает множественные bucket'ы. Вы можете настроить их в настройках соединения.
s3.multibucket.update.title=Новые S3 функции в BigDataTools
scala.serializable.scope.inspection.description=Подсветка несериализуемых значений в области действия spark задач, которые приведут к исключению во время выполнения.
scala.serializable.scope.inspection.warning=<html>Несериализуемое значение {0} типа {1} в Spark области {2}</html>
scala.wrong.path.inspection.description=Подсветка некорректных hdfs путей в Scala коде
settings.alibaba.region=Регион\:
settings.azure.auth.type=Тип аутентификации\:
settings.azure.connection.string=Строка подключения\:
settings.azure.container=Контейнер\:
settings.azure.endpoint=Endpoint\:
settings.azure.password=Пароль\:
settings.azure.sas.token=SAS токен\:
settings.azure.user.key=Ключ\:
settings.azure.username=Имя пользователя\:
settings.bucket.filter=Фильтр bucket'ов\:
settings.bucket.filter.type=Тип фильтра\:
settings.buckets.custom.list=Пользовательские корни
settings.buckets.hint=<html><b>Все bucket'ы в аккаунте</b> - выполняет запрос <it>list buckets</it>. Позволяет фильтровать результирующий список bucket'ов.<br><br><b>Пользовательские корни</b> - напрямую запрашивает выбранные корни, позволяя указать не только bucket'ы, но и полные пути к директориям.</html>
settings.buckets.user.list=Все bucket'ы в аккаунте
settings.config.from.folder=Разобранная конфигурация\:
settings.config.path=Путь конфигурации\:
settings.custom.roots=Корни\:
settings.generate.kerberos=Kerberos
settings.hdfs.auth.type=Аутентификация\:
settings.hdfs.kerberos.type=Метод аутентификации\:
settings.hdfs.kinit=Использовать kinit кэш
settings.hdfs.url=URI кластера\:
settings.hdfs.username=Hadoop пользователь\:
settings.hdfs.username.hint=Имя пользователя для входа на сервер. Если не указано, используется переменная окружения <i>HADOOP_USER_NAME</i>. Если она не определена, используется свойство <i>user.name</i>. Если включен Kerberos, он переопределяет все три значения.
settings.kerberos.auth=Аутентификация\:
settings.kerberos.auth.kerberos=Kerberos
settings.kerberos.auth.none=Нет
settings.minio.endpoint=Endpoint\:
settings.properties=Расширенная конфигурация\:
settings.s3.bucket.filter.by.region=Только bucket'ы в выбранном регионе
settings.s3.custom.endpoint=Endpoint\:
settings.s3.custom.region=Регион\:
settings.s3.custom.region.hint=Использовать при необходимости
settings.s3.region=Регион\:
settings.s3.region.group=AWS S3
settings.s3.selection.endpoint=S3-совместимое хранилище
settings.undefined.path=<не инициализовано>
settings.validation.kerberos.keytab.error=Необходимо указать keytab и principal
settings.validation.kerberos.password.error=Необходимо указать principal и пароль
setup.video.tutor=Видео-руководство по настройке подключения
ssh.additional.info=SSH туннель <b>работает только для операций с NameNode</b>\: листинг файлов, получение метаинформации.<br><br>
ssh.additional.label=(только для операций с NameNode)
wrong.region=Регион "{0}" не найден