action.BigDataTools.CreateClusterConnectionsAction.text=Новое подключение
action.BigDataTools.Deploy.Configure.text=Создать конфигурацию Spark Submit…
add.new.arbitrary.cluster.submit.connection.label=Добавить произвольный Spark кластер…
add.new.ssh.connection.label=Добавить SSH подключение…
app.by.me.value=Мной
arbitrary.cluster.wizard.create.connection.title=Произвольный Spark кластер
arbitrary.cluster.wizard.default.radio.button=Использовать настройки по умолчанию
arbitrary.cluster.wizard.select.sftp.step.desc=Настроить SFTP подключение к узлу драйвера
arbitrary.cluster.wizard.select.sftp.step.title=SFTP
arbitrary.cluster.wizard.select.spark.step.desc=Настроить подключение к Spark History Server
arbitrary.cluster.wizard.select.spark.step.title=Spark
arbitrary.cluster.wizard.select.ssh.step.desc=Указать SSH конфигурацию для использования Spark-Submit
arbitrary.cluster.wizard.select.ssh.step.title=SSH
arbitrary.cluster.wizard.sftp.custom.radio.button=Настроить пользовательское подключение
arbitrary.cluster.wizard.sftp.none.radio.button=SFTP подключение к узлу драйвера не требуется
arbitrary.cluster.wizard.spark.custom.radio.button=Настроить пользовательское подключение
arbitrary.cluster.wizard.spark.none.radio.button=Подключение к Spark History Server не требуется
arbitrary.cluster.wizard.spark.step.default.uri.comment.text=(localhost на туннельном хосте)
artifact.tooltip=Путь к исполняемому файлу для запуска на кластере
check.connection.availability=Проверить доступность подключения
check.ssh.connection.ssh.is.not.defined=SSH конфигурация не указана
cluster.manager.kubernetes=Kubernetes
cluster.manager.local=Локальный
cluster.manager.mesos=Apache Mesos
cluster.manager.nomad=Nomad
cluster.manager.standalone=Автономный
cluster.manager.tooltip=Менеджер кластера, настроенный на сервере.
cluster.manager.yarn=Hadoop YARN
cluster.status.loading=Загрузка…
cluster.status.no.target=<нет цели>
cluster.status.not.selected=<Не выбрано>
configuration.description=Конфигурация Spark Submit
configuration.name=Spark Submit
configuration.name.cluster=Кластер
configuration.name.local=Локальный (устарело)
configuration.name.python=PySpark
configuration.name.ssh=SSH (устарело)
configuration.options.add=Дополнительные настройки
configuration.options.add.title=Добавить параметры запуска
dialog.archives.title=Выбрать архивы
dialog.artifactPath.title=Выбрать приложение
dialog.driverClassPath.title=Выбрать classpath драйвера
dialog.driverLibraryPath.title=Выбрать путь к библиотекам драйвера
dialog.files.title=Выбрать файлы
dialog.input.spark.command.description=Вставьте команду spark-submit здесь для заполнения формы Spark Submit
dialog.input.spark.command.label=Spark команда
dialog.input.spark.command.title=Spark ввод
dialog.jars.title=Выбрать Jar файлы
dialog.keytabFile.title=Выбрать keytab файл
dialog.message.adding.other.configurations.not.allowed.here=Добавление других конфигураций здесь не разрешено.
dialog.message.failed.to.create.ssh.process=Не удалось создать SSH процесс
dialog.message.not.found=Не найдено {0}
dialog.message.spark.home.should.be.set.to.correct.folder=$SPARK_HOME должен быть установлен в правильную папку.
dialog.message.specify.application=Укажите приложение
dialog.message.ssh.configuration.changed=Вы выбрали другую SSH конфигурацию для кластера {0}.
dialog.propertiesFile.title=Выбрать файл свойств
dialog.pyfiles.title=Выбрать Python файлы
dialog.select.artifact.button.open.artifact.settings=Настройки артефактов
dialog.select.artifact.empty=Нет артефактов в текущем проекте
dialog.select.artifact.link.open.artifact.settings=Настроить артефакты
dialog.select.artifact.title=Выбрать артефакт зависимости
dialog.select.class.empty=Классы не найдены в выбранном приложении
dialog.select.class.title=Имя класса
dialog.sparkHomePath.title=Выбрать домашнюю директорию Spark
dialog.targetDirectory.title=Выбрать целевую директорию
dialog.title.select.gradle.artifact.with.task=Выбрать Gradle артефакт и задачу
dialog.title.ssh.configuration.changed=SSH конфигурация изменена
dialog.workDir.title=Выбрать рабочую директорию
edit.ssh.configuration=Редактировать SSH конфигурацию
error.ssh=Укажите SSH конфигурацию
error.ssh.config=SSH конфигурация должна быть указана
error.target.config=Выберите удалённую цель
error.target.config.unresolved=Выберите действительную удалённую цель
exportable.SparkSubmitSettings.presentable.name=Настройки Big Data Tools Spark Submit
fun.search.process.text=Процесс {0}
group.ServiceView.AddSparkService.text=Spark кластер
inlay.attach.debugger.ssh=Подключить отладчик через SSH туннель
label.implicit.cluster.depend.sftp=SFTP\:
label.implicit.cluster.depend.spark.connection=Spark History\:
label.select.ssh.configuration.for.cluster=Выберите SSH конфигурацию для кластера {0}
load.command.string=Загрузить команду spark-submit
notification.group.sftpsparkfileupload=Загрузка файлов SFTP для Spark
open.cluster.info.description=Нажмите для открытия документации
progress.text.upload.to.host=Загрузка {0} на хост…
pyspark=PySpark
pyspark.documentation.dataframe.schema=Столбцы\: {0}
receive.artifact.task=Получение артефакта…
remote.target.arbitrary.cluster.remark=Произвольный кластер
remote.target.ssh.remark=SSH
replace.with.allowed.value=Заменить допустимым значением
row.final.command=Итоговая команда запуска
row.final.command.copy=Копировать команду spark-submit
row.final.command.hint=Вы можете скопировать или загрузить команду spark-submit, которая заполнит соответствующие поля
services.error.create.spark.connection.canceled.fix.label=Попробовать перезагрузить
services.error.create.spark.connection.canceled.message=Отменено пользователем
services.error.ssh.config.is.not.found=SSH конфигурация не найдена
services.error.top.cannot.create.spark.connection=Не удаётся создать Spark подключение
services.spark.connection.is.not.created=Не удалось создать Spark подключение
settings.additional.title=Расширенные параметры запуска
settings.additional.verbose=Выводить дополнительную отладочную информацию
settings.application=Приложение\:
settings.application.arguments=Аргументы запуска\:
settings.application.class.hint=Главный класс вашего приложения для --class (для Java/Scala приложений).
settings.application.class.name=Класс\:
settings.application.class.name.error.msg=Сначала укажите приложение
settings.application.class.name.error.title=Ошибка выбора класса
settings.application.hint=Аргументы для метода main главного класса (если есть).
settings.beforeShellScript=Перед скриптом запуска
settings.beforeShellScript.hint=Скрипт для выполнения перед Spark Submit. Например, "source activate py36"
settings.cluster.manager=Менеджер кластера\:
settings.cluster.manager.proxy.user=Прокси-пользователь\:
settings.cluster.manager.proxy.user.hint=<html>--proxy-user Пользователь, от имени которого запускать приложение.<br>Этот аргумент не влияет на --principal/--keytab.</html>
settings.cluster.manager.queue=Очередь\:
settings.cluster.manager.queue.hint=--queue YARN очередь для отправки (по умолчанию\: "default").
settings.cluster.manager.supervise=Включить мониторинг
settings.cluster.manager.supervise.hint=--supervise Если задано, перезапускает драйвер при сбое.
settings.debug.driver.in.debug.mode=В режиме отладки
settings.debug.driver.in.run.mode=В режиме запуска
settings.debug.driver.java.enable=Запустить Spark драйвер с отладочным агентом
settings.debug.driver.java.not.supported=Отладка не поддерживается в режиме кластерного развертывания
settings.debug.driver.java.port=Прослушиваемый порт\:
settings.debug.driver.java.port.dynamic=<динамический>
settings.debug.driver.java.suspend=Приостановить драйвер\:
settings.debug.driver.java.suspend.tooltip=Приостановить процесс Spark драйвера до подключения отладчика
settings.debug.driver.java.tooltip=Добавить '-agentlib\:jdwp' к Java опциям драйвера
settings.debug.title=Отладка Spark
settings.dependencies.files=Файлы\:
settings.dependencies.files.hint=--files Список файлов через запятую для размещения в рабочей директории каждого executor. Доступ к путям этих файлов в executor через SparkFiles.get(fileName).
settings.dependencies.jars=Jar\:
settings.dependencies.jars.hint=--jars Список jar-файлов через запятую для включения в classpath драйвера и executor.
settings.dependencies.python=Py файлы\:
settings.dependencies.python.hint=--py-files Список .zip, .egg или .py файлов через запятую для добавления в PYTHONPATH Python приложения.
settings.dependencies.title=Зависимости
settings.deploy.mode=Режим развертывания\:
settings.deploy.mode.hint=<html>--deploy-mode Запускать драйвер локально ("client") или на одной из рабочих машин<br>внутри кластера ("cluster").</html>
settings.deploymode.client=Клиент
settings.deploymode.cluster=Кластер
settings.driver.class.path=Classpath драйвера\:
settings.driver.class.path.hint=<html>--driver-class-path Дополнительные элементы classpath для драйвера<br>Обратите внимание, что jar-файлы добавленные через --jars автоматически включаются в classpath.</html>
settings.driver.cores=Ядра драйвера\:
settings.driver.cores.hint=--driver-cores Количество ядер для драйвера, только в кластерном режиме.
settings.driver.java.options=Java опции драйвера\:
settings.driver.java.options.hint=--driver-java-options Дополнительные Java опции для драйвера.
settings.driver.library.path=Library path драйвера\:
settings.driver.library.path.hint=--driver-library-path Дополнительные пути к библиотекам для драйвера.
settings.driver.memory=Память драйвера\:
settings.driver.memory.hint=--driver-memory Память для драйвера (например, 1000M, 2G).
settings.driver.title=Драйвер
settings.envParams=Переменные окружения
settings.envParams.hint=Дополнительные переменные окружения
settings.executor.archives=Архивы\:
settings.executor.archives.hint=<html>--archives Список архивов для извлечения в рабочую директорию каждого executor.</html>
settings.executor.cores=Ядра executor\:
settings.executor.cores.hint=<html>--executor-cores Количество ядер на executor<br>(по умолчанию\: 1 в режиме YARN, все доступные ядра на worker в standalone режиме).</html>
settings.executor.cores.total=Всего ядер executor\:
settings.executor.cores.total.hint=--total-executor-cores Общее количество ядер для всех executor.
settings.executor.memory=Память executor\:
settings.executor.memory.default=1G
settings.executor.memory.hint=--executor-memory Память на executor (например\: 1000M, 2G)
settings.executor.number=Количество executor\:
settings.executor.number.hint=<html>--num-executors Количество executor для запуска<br>При включенном динамическом выделении, начальное количество executor будет не меньше этого значения.</html>
settings.executor.title=Executor
settings.integration.spark.monitoring=Подключение\:
settings.integration.spark.monitoring.add=Добавить
settings.integration.title=Интеграция мониторинга Spark
settings.isInteractive=Интерактивный режим
settings.isInteractive.hint=Выполнять команды в интерактивном режиме shell
settings.kerberos.keytab=Keytab\:
settings.kerberos.keytab.hint=<html>--keytab Полный путь к файлу keytab, содержащему принципала указанного выше<br>Этот keytab будет скопирован через Secure Distributed Cache на узел, запускающий Application Master,<br>для периодического обновления login ticket и delegation token.</html>
settings.kerberos.principal=Принципал\:
settings.kerberos.principal.hint=--principal Принципал для входа в KDC при работе с защищенной HDFS.
settings.kerberos.title=Kerberos
settings.master=Master\:
settings.master.hint=--master spark\://host\:port, mesos\://host\:port, yarn, k8s\://https\://host\:port, или local (по умолчанию\: local[*]).
settings.maven.exclude.packages=Исключить пакеты\:
settings.maven.exclude.packages.hint=<html>--exclude-packages Список groupId\:artifactId для исключения при разрешении зависимостей<br>указанных в --packages во избежание конфликтов зависимостей.</html>
settings.maven.packages=Пакеты\:
settings.maven.packages.hint=<html>--packages Список Maven координат jar-файлов для включения в classpath драйвера и executor<br>Поиск выполняется в локальном Maven репозитории, затем в Maven Central и других удалённых репозиториях из --repositories<br>Формат координат должен быть groupId\:artifactId\:version.</html>
settings.maven.repositories=Репозитории\:
settings.maven.repositories.hint=--repositories Список дополнительных удалённых репозиториев для поиска Maven координат из --packages.
settings.maven.title=Maven
settings.run.target.config=Удалённая цель\:
settings.run.target.tooltip=Выберите Spark кластер для запуска приложения
settings.shell.title=Опции Shell
settings.shellExecutor=Путь к Shell
settings.shellExecutor.hint=Путь к shell. Используется при включенном интерактивном режиме или перед установкой скрипта отправки
settings.spark.config=Конфигурация\:
settings.spark.config.hint=--conf Свойства конфигурации Spark.
settings.spark.home=Домашняя директория Spark\:
settings.spark.properties.file=Файл свойств\:
settings.spark.properties.file.hint=<html>--properties-file Путь к файлу для загрузки дополнительных свойств.<br>Если не указан, ищется conf/spark-defaults.conf.</html>
settings.spark.python.sdk=Запустить с Python окружением\:
settings.spark.title=Конфигурация Spark
settings.ssh.config=SSH конфигурация\:
settings.ssh.error.msg=Сначала выберите SSH конфигурацию
settings.ssh.error.title=Ошибка выбора файла
settings.ssh.target.dir=Целевая директория загрузки\:
settings.ssh.target.dir.hint=<html>Введите путь к директории на удалённом хосте, куда будут загружены все локальные файлы.<br>Если выбранные файлы уже существуют в этой директории, они будут перезаписаны.</html>
settings.ssh.title=Опции SFTP
settings.url.artifact.name=ИСРA артефакт
settings.url.artifact.tooltip=ИСРA артефакт
settings.url.custom.name=Пользовательский
settings.url.file.name=Файл
settings.url.gcs.name=GC Storage
settings.url.gcs.tooltip=GC Storage
settings.url.gradle.artifact.name=Gradle артефакт
settings.url.gradle.artifact.tooltip=Gradle артефакт
settings.url.hdfs.name=HDFS
settings.url.maven.artifact.name=Maven артефакт
settings.url.maven.artifact.tooltip=Maven артефакт
settings.url.s3.name=S3
settings.url.server.mock.desc=Путь к файлу\:
settings.url.server.name=Файл на сервере
settings.url.server.tooltip=Файл на сервере
settings.url.upload.name=Загрузить файл
settings.url.upload.tooltip=Загрузить локальный файл
settings.url.web.name=Удалённый
settings.workingDirectory=Рабочая директория
setup.ssh.config=Настроить SSH конфигурацию
spark.converter.build.run.configuration.description=Конфигурация запуска 'PySpark' изменилась. Требуется конвертация существующих конфигураций.
spark.submit.gutter.icon.tooltip=Запустить на Spark кластере
sparkhome.tooltip=Директория Spark
upload.file.title=Загрузить файл на удалённый хост
upload.files.error=Произошла ошибка при загрузке файлов. {0}
upload.files.success=Успешно загружено {0} файлов
upload.files.through.sftp.to.spark.host=Загрузка файлов через SFTP
upload.target.dir.is.not.found=Целевая директория "{0}" не найдена
work.directory.tooltip=Указывает на место вызова скрипта