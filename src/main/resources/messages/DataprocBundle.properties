action.add.job.title=Отправить задачу
action.cancel.job.confirm.msg=Отменить задачу "{0}"?
action.cancel.job.title=Отменить задачу
action.clone.job.title=Клоновать задачу
action.cluster.remove.confirm.msg=Удалить кластер "{0}"?
action.cluster.start.confirm.msg=Запустить кластер "{0}"?
action.cluster.terminate.confirm.msg=Завершить работу кластера "{0}"?
action.confirm.title=Подтверждение
action.delete.job.confirm.msg=Удалить задачу "{0}"?
action.delete.job.title=Удалить задачу
action.open.stage.bucket=Открыть staging bucket
action.sftp=Открыть SFTP к узлу
action.sftp.master.node=Открыть SFTP к мастер-узлу
action.ssh=Открыть SSH к узлу
action.ssh.master.node=Подключиться к мастер-узлу по SSH
add.job.title=Отправить задачу
add.new.submit.connection.label=Добавить подключение Dataproc…
cell.execution.finished.msg=Задача "{0}" завершена со статусом {1}.
cell.execution.finished.title=Задача Dataproc
cluster.action.delete=Удалить кластер
cluster.action.start=Запустить кластер
cluster.action.stop=Завершить работу кластера
cluster.info.config.autoscaling=Автомасштабование\:
cluster.info.config.master.node.desc=Мастер-узел\:
cluster.info.config.metastore=Metastore Dataproc\:
cluster.info.config.monitoring=Мониторинг целостности\:
cluster.info.config.network=Сеть\:
cluster.info.config.region=Регион\:
cluster.info.config.scheduled.deletion=Запланованное удаление\:
cluster.info.config.secure.boot=Secure Boot\:
cluster.info.config.vtpm=VTPM\:
cluster.info.config.worker.node.desc=Worker-узлы\:
cluster.info.config.zone=Зона доступности
cluster.info.image.created=Время создания\:
cluster.info.image.version=Версия образа\:
cluster.info.internal.ip=Только внутренний IP\:
cluster.info.optional.components=Опциональные компоненты\:
cluster.info.summary.name=Имя\:
cluster.info.summary.state=Состояние\:
cluster.info.summary.state.details=Детали состояния\:
cluster.info.summary.type=Тип\:
cluster.info.summary.uiid=UUID кластера\:
cluster.tab.applications.title=Приложения
cluster.tab.info.title=Информация
cluster.tab.jobs.title=Задачи
cluster.tab.name=Кластер
cluster.tab.vb.instances.title=VM-экземпляры
data.clusterInfo.created=Создан
data.clusterInfo.id=ID
data.clusterInfo.name=Имя
data.clusterInfo.region=Регион
data.clusterInfo.scheduledDeletion=Запланованное удаление
data.clusterInfo.stagingBucket=Staging bucket
data.clusterInfo.state=Состояние
data.clusterInfo.totalWorkers=Всего worker-узлов
data.clusterInfo.zone=Зона
data.jobInfo.cluster=Кластер
data.jobInfo.elapsedTime=Прошло времени
data.jobInfo.id=ID
data.jobInfo.labels=Метки
data.jobInfo.startTime=Время начала
data.jobInfo.status=Статус
data.jobInfo.type=Тип
data.vm.instanceInfo.componentGateway=Component Gateway
data.vm.instanceInfo.name=Имя
data.vm.instanceInfo.url=URL
data.web.interfaceInfo.name=Имя
data.web.interfaceInfo.role=Роль
datamanager.configuration=Конфигурация
datamanager.job.info=Информация о задаче
datamanager.labels=Метки
datamanager.properties=Свойства
datamanager.summary=Сводка
dataproc.error=Ошибка Dataproc
dataproc.error.cluster.must.be.started=Кластер должен быть запущен.
dataproc.toolwindow.title=GC Dataproc
default.gcs.connection.name=Проект GC Dataproc
emr.remove.linked.connections.title=Подключение Dataproc
error.connection.is.not.found=Подключение для Dataproc не настроено. Пожалуйста, создайте его заново.
error.json.auth.limited.msg=Эта операция доступна только при аутентификации в Dataproc через gcloud CLI
error.json.auth.limited.title=Операция недоступна
error.spark.is.not.found=Кластер не содержит Spark History Server
exportable.DataprocSettings.presentable.name=Настройки Big Data Tools Dataproc
exportable.DataprocSshKeyPaths.presentable.name=Настройки SSH Big Data Tools Dataproc
group.name.dataproc=GC Dataproc
info.value.off=Выкл
instance.config.gpu.number=Количество GPU
instance.config.local.ssd=Локальный SSD
instance.config.machineType=Тип машины\:
instance.config.primary.disk.size=Размер основного диска\:
instance.config.primary.disk.type=Тип основного диска\:
job.hadoop.title=Hadoop
job.hive.title=Hive
job.info.client.tags=Клиентские теги
job.info.cluster=Кластер\:
job.info.continue.on.failure=Продолжить при ошибке
job.info.elapsed.time=Прошло времени\:
job.info.jobId=ID задачи\:
job.info.jobUuid=UUID задачи\:
job.info.max.restart.per.hour=Макс. перезапусков в час\:
job.info.max.restart.per.hour.hint=Оставьте пустым, если не хотите автоматического перезапуска при сбое.
job.info.open.job.files=Показать папку задачи в GCS
job.info.properties=Свойства
job.info.query.file=Запрос\:
job.info.query.file.value=Файл запроса\:
job.info.query.text.value=Текст запроса\:
job.info.query.type=Источник запроса\:
job.info.single.file.hint=Может быть файл GCS с префиксом gs\://, файл HDFS на кластере с префиксом hdfs\:// или локальный файл на кластере с префиксом file\://
job.info.spark.additional.py.files=Дополнительные Python файлы\:
job.info.spark.additional.py.files.title=Выбрать дополнительные Py файлы
job.info.spark.additional.r.files=Дополнительные R файлы\:
job.info.spark.additional.r.files.title=Выбрать дополнительные R файлы
job.info.spark.archives=Архивы\:
job.info.spark.archives.hint=Архивные файлы распаковываются в рабочей директории Spark. Может быть файл GCS с префиксом gs\://, файл HDFS на кластере с префиксом hdfs\:// или локальный файл на кластере с префиксом file\://. Поддерживаемые типы файлов\: .jar, .tar, .tar.gz, .tgz, .zip.
job.info.spark.archives.title=Выбрать архивы
job.info.spark.args=Аргументы\:
job.info.spark.files=Файлы\:
job.info.spark.jars=Jar\:
job.info.spark.jars.hint=Jar файлы включаются в CLASSPATH. Может быть файл GCS с префиксом gs\://, файл HDFS на кластере с префиксом hdfs\:// или локальный файл на кластере с префиксом file\://.
job.info.spark.jars.title=JAR
job.info.spark.main.class=Main класс\:
job.info.spark.main.py.file.title=Выбрать главный Py файл
job.info.spark.main.pyfile=Главный Python файл\:
job.info.spark.main.r.file=Главный R файл\:
job.info.spark.main.r.file.title=Выбрать главный R файл
job.info.start.date=Дата начала\:
job.info.status=Статус\:
job.info.status.details=Детали статуса\:
job.info.type=Тип задачи\:
job.label.block.title=Метки
job.pig.title=Pig
job.presto.title=Presto
job.properties.block.title=Свойства
job.pyspark.title=PySpark
job.query.file.dialog.title=Выбрать файл запроса\:
job.query.file.label=Файл запроса\:
job.query.source.file=Файл
job.query.source.text=Текст
job.query.source.type=Тип запроса\:
job.query.text.hint=Запрос для выполнения
job.query.text.label=Текст запроса\:
job.spark.r.title=SparkR
job.spark.sql.title=SparkSql
job.spark.title=Spark
job.state.active=Активна
job.state.canceled=Отменена
job.state.done=Завершена
job.state.failed=Сбой
job.validation.file.archive={0} должен быть архивом типа .jar, .tar, .tar.gz, .tgz, .zip.
job.validation.file.fs={0} должен быть файлом с префиксом gs\://, hdfs\:// или file\://
metainfo.cluster.id=ID\:
metainfo.cluster.name=Имя\:
metainfo.cluster.status=Статус\:
remote.target.emr.cluster.remark=Dataproc
resolve.artifact.is.not.supported=Определение main класса для {0} не поддерживается.
settings.application.class.name.error.msg=Сначала выберите jar файл
task.init.ssh.perform.cli.command=Выполнение команды GCloud CLI…
task.init.ssh.title=Выполнение Dataproc CLI